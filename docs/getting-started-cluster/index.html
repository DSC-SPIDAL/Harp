<!DOCTYPE html><html lang="en-us"><head><link rel="shortcut icon" type="image/png" sizes="16x16" href="https://dsc-spidal.github.io/harp/img/favicon-16x9.png"><link rel="shortcut icon" type="image/png" sizes="32x32" href="https://dsc-spidal.github.io/harp/img/favicon-32x18.png"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Hugo 0.18" /><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="harp"><meta property="og:image" content="/img/logo54x54.png"><meta property="og:url" content="https://dsc-spidal.github.io/harp/"><meta name="twitter:title" content="harp"><meta name="twitter:image" content="/img/0-1-1.png"><meta property="og:site_name" content="Quick Start Guide"><meta property="og:url" content="/docs/getting-started-cluster/"><meta property="og:description" content="Run multi-node Harp on clusters"><meta name="twitter:description" content="Run multi-node Harp on clusters"><title>harp Documentation - Quick Start Guide</title><link rel="stylesheet" href="https://dsc-spidal.github.io/harp/css/style.min.css"><link rel="stylesheet" href="https://dsc-spidal.github.io/harp/css/font-awesome.min.css"><link rel="stylesheet" href="https://dsc-spidal.github.io/harp/css/pygments.css"></head><body><nav class="hn-top-navbar navbar navbar-inverse navbar-fixed-top" role="navigation"><div class="hn-navbar-container container-fluid"><div class="navbar-header"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#hn-navbar" aria-controls="hn-navbar" aria-expanded="false"><span class="sr-only"><Toggle>navigation</Toggle></span><i class="hn-toggle-button fa fa-bars"></i></button><a class="hn-navbar-logo navbar-brand" href="https://dsc-spidal.github.io/harp/"><img class="pull-left" src="https://dsc-spidal.github.io/harp/img/0-1-2.png"></a></div><div id="hn-navbar" class="navbar-collapse collapse"><ul class="nav navbar-nav navbar-right"><li><a href="https://dsc-spidal.github.io/harp/docs/getting-started">Docs</a></li><li><a href="https://dsc-spidal.github.io/harp/api">API</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/resources">Resources</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/contributors/community">Community</a></li><li><a href="https://github.com/DSC-SPIDAL/harp/">GitHub</a></li><li><a href="https://groups.google.com/forum/#!forum/harp-users">Mailing List</a></li></ul></div></div></nav><div class="hn-main"><div class="container"><div class="row"><aside class="hn-sidebar hidden-xs col-sm-4 col-md-3 col-lg-2 collapse"><nav class="hn-sidebar-nav"><div id="hn-accordion" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="quick-start" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-quick-start" aria-labelledby="quick-start"><i class="fa fa-caret-right"></i>Quick Start</a></h4></section><div id="collapse-quick-start" class="panel-collapse collapse" aria-labelledby="quick-start"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/getting-started">Harp Installation (single)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/getting-started-cluster">Harp Installation (cluster)</a></li></ul></div></div></div><div class="panel panel-default"><section id="programming-guides" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-programming-guides" aria-labelledby="programming-guides"><i class="fa fa-caret-right"></i>Programming Guides</a></h4></section><div id="collapse-programming-guides" class="panel-collapse collapse" aria-labelledby="programming-guides"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/programming/overview">Overview</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/programming/data-interface">Data Interfaces and Types</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/programming/scheduler">Schedulers</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/programming/computation-models">Computation Models</a></li></ul></div></div></div><div class="panel panel-default"><section id="collective-communication" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-collective-communication" aria-labelledby="collective-communication"><i class="fa fa-caret-right"></i>Collective Communication</a></h4></section><div id="collapse-collective-communication" class="panel-collapse collapse" aria-labelledby="collective-communication"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/communications/broadcast">broadcast</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/reduce">reduce</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/allgather">allgather</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/allreduce">allreduce</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/regroup">regroup</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/pushandpull">push &amp; pull</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/rotate">rotate</a></li></ul></div></div></div><div class="panel panel-default"><section id="examples" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-examples" aria-labelledby="examples"><i class="fa fa-caret-right"></i>Examples</a></h4></section><div id="collapse-examples" class="panel-collapse collapse" aria-labelledby="examples"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/examples/overview">Overview</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/kmeans">K-Means</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/mlrsgd">Multiclass Logistic Regression</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/lda">Latent Dirichlet Allocation (CVB)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/svm">Support Vector Machine</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/rf">Random Forests</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/nn">Neural Network</a></li></ul></div></div></div><div class="panel panel-default"><section id="applications" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-applications" aria-labelledby="applications"><i class="fa fa-caret-right"></i>Applications</a></h4></section><div id="collapse-applications" class="panel-collapse collapse" aria-labelledby="applications"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/applications/lda-cgs">Latent Dirichlet Allocation (CGS)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/applications/mf">Matrix Factorization</a></li></ul></div></div></div><div class="panel panel-default"><section id="harp-daal" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-harp-daal" aria-labelledby="harp-daal"><i class="fa fa-caret-right"></i>Harp-DAAL</a></h4></section><div id="collapse-harp-daal" class="panel-collapse collapse" aria-labelledby="harp-daal"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/harpdaal">Overview</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/mfsgd">Matrix Factorization (SGD)</a></li></ul></div></div></div><div class="panel panel-default"><section id="harp-resources" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-harp-resources" aria-labelledby="harp-resources"><i class="fa fa-caret-right"></i>Harp Resources</a></h4></section><div id="collapse-harp-resources" class="panel-collapse collapse" aria-labelledby="harp-resources"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/resources">Harp Resources</a></li></ul></div></div></div><div class="panel panel-default"><section id="contributors" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion" href="#collapse-contributors" aria-labelledby="contributors"><i class="fa fa-caret-right"></i>Contributors</a></h4></section><div id="collapse-contributors" class="panel-collapse collapse" aria-labelledby="contributors"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/contributors/community">Community</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/contributors/contributors">Contributors</a></li></ul></div></div></div></div></nav></aside><section class="hn-docs-main col-sm-8 col-md-9 col-lg-10 col-sm-offset-4 col-md-offset-3 col-lg-offset-2"><header class="hn-docs-header page-header"><h1>Quick Start Guide</h1><div class="hn-docs-description">Run multi-node Harp on clusters</div></header><article class="hn-docs-content">

<p>These instructions have only been tested on:</p>

<ul>
<li>Red Hat Enterprise Linux Server release 6.8</li>
</ul>

<h2 id="step-1-install-hadoop-2-6-0">Step 1 &mdash; Install Hadoop 2.6.0</h2>

<ol>
<li><p>Make sure your computer can use <code>ssh</code> to access each node in the cluster and can install <code>Java</code> as well.</p></li>

<li><p>Download and extract the hadoop-2.6.0 binary into your machine. It&rsquo;s available at <a href="https://dist.apache.org/repos/dist/release/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz">hadoop-2.6.0.tar.gz</a>.</p></li>

<li><p>Set the environment variables in <code>~/.bashrc</code>.</p>
export JAVA_HOME=<where Java locates>
#e.g. ~/jdk1.8.0_91
export HADOOP_HOME=<where hadoop-2.6.0 locates>
#e.g. ~/hadoop-2.6.0
export YARN_HOME=$HADOOP_HOME
export PATH=$HADOOP_HOME/bin:$JAVA_HOME/bin:$PATH
source $HADOOP_HOME/etc/hadoop/hadoop-env.sh
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</li>

<li><p>Run to test if the changes are applied.</p>
$ source ~/.bashrc</li>

<li><p>Check if environment variabls are set correctly.</p>
$ hadoop
Usage: hadoop [--config confdir] COMMAND
   where COMMAND is one of:
fs                   run a generic filesystem user client
version              print the version
jar <jar>            run a jar file
checknative [-a|-h]  check native hadoop and compression libraries availability
distcp <srcurl> <desturl> copy file or directories recursively
archive -archiveName NAME -p <parent path> <src>* <dest> create a hadoop archive
classpath            prints the class path needed to get the
credential           interact with credential providers
                   Hadoop jar and the required libraries
daemonlog            get/set the log level for each daemon
trace                view and modify Hadoop tracing settings
or
CLASSNAME            run the class named CLASSNAME
Most commands print help when invoked w/o parameters.</li>

<li><p>Modify the following files in Apache Hadoop distribution:</p>

<p>(1).<code>$HADOOP_HOME/etc/hadoop/core-site.xml</code>:</p>
<configuration>
<property>
<name>fs.default.name</name>
<value>hdfs://${namenode}:9010</value>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>/tmp/hadoop-${user name}</value>
<description>A base for other temporary directories.</description>
</property>
</configuration>

<p>(2).<code>$HADOOP_HOME/etc/hadoop/hdfs-site.xml</code>:</p>
<configuration>
<property>
<name>dfs.hosts</name>
<value>${HADOOP_HOME}/etc/hadoop/slaves</value>
</property>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.http-address</name>
<value>${namenode}:50271</value>
</property>
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>${namenode}:50291</value>
</property>
</configuration>

<p>(3).<code>$HADOOP_HOME/etc/hadoop/mapred-site.xml</code>:
You will be creating this file. It doesn’t exist in the original package.</p>
<configuration>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
<property>
<name>mapreduce.map.collective.memory.mb</name>
<value>100000</value>
</property>
<property>
<name>mapreduce.map.collective.java.opts</name>
<value>-Xmx90000m -Xms90000m</value>
</property>
</configuration>

<p>(4).<code>$HADOOP_HOME/etc/hadoop/yarn-site.xml</code>:</p>
<configuration>
<property>
<name>yarn.resourcemanager.hostname</name>
<value>${namenode}</value>
</property>
<property>
<name>yarn.resourcemanager.address</name>
<value>${namenode}:8132</value>
</property>
<property>
<name>yarn.resourcemanager.scheduler.address</name>
<value>${namenode}:8230</value>
</property>
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<property>
<name>yarn.nodemanager.log-dirs</name>
<value>/tmp/hadoop-${user name}</value>
</property>
<property>
<name>yarn.scheduler.maximum-allocation-mb</name>
<value>128000</value>
</property>
<property>
<name>yarn.nodemanager.resource.memory-mb</name>
<value>120000</value>
</property>
<property>
<name>yarn.nodemanager.delete.debug-delay-sec</name>
<value>10000000</value>
</property>
</configuration>

<p>(5).<code>$HADOOP_HOME/etc/hadoop/slaves</code>:</p>
${namenode}
${other node 1}
${other node 2}
...</li>

<li><p>Format the file system and you should be able to see it exits with status 0.</p>
$ hdfs namenode -format
...
xx/xx/xx xx:xx:xx INFO util.ExitUtil: Exiting with status 0
xx/xx/xx xx:xx:xx INFO namenode.NameNode: SHUTDOWN_MSG:
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at xxx.xxx.xxx.xxx</li>

<li><p>Launch NameNode daemon, DataNode daemon, ResourceManager daemon and NodeManager Daemon.</p>
$ $HADOOP_HOME/sbin/start-dfs.sh
$ $HADOOP_HOME/sbin/start-yarn.sh</li>

<li><p>Check if the daemons started successfully with the following output:</p>
$ jps
xxxxx NameNode
xxxxx SecondaryNameNode
xxxxx DataNode
xxxxx NodeManager
xxxxx Jps
xxxxx ResourceManager</li>
</ol>

<h2 id="step-2-install-harp">Step 2 &mdash; Install Harp</h2>

<ol>
<li><p>Clone Harp repository. It is available at <a href="https://github.com/DSC-SPIDAL/harp.git">DSC-SPIDAL/harp</a>.</p>
$ git clone git@github.com:DSC-SPIDAL/harp.git</li>

<li><p>Follow the <a href="http://maven.apache.org/install.html">maven official instruction</a> to install maven.</p></li>

<li><p>Add environment variables in <code>~/.bashrc</code>.</p>
export HARP_ROOD_DIR=<where Harp locates>
#e.g. harp/harp-project
export HARP_HOME=$HARP_ROOD_DIR/harp-project</li>

<li><p>Run source command to set the envrionment variables.</p>
$ source ~/.bashrc</li>

<li><p>Stop hadoop first if it is still running.</p>
$ $HADOOP_HOME/sbin/stop-dfs.sh
$ $HADOOP_HOME/sbin/stop-yarn.sh</li>

<li><p>Enter &ldquo;harp&rdquo; home directory.</p>
$ cd $HARP_ROOT_DIR</li>

<li><p>Compile harp.</p>
$ mvn clean package</li>

<li><p>Install harp plugin to hadoop.</p>
$ cp harp-project/target/harp-project-1.0-SNAPSHOT.jar $HADOOP_HOME/share/hadoop/mapreduce/
$ cp third_party/fastutil-7.0.13.jar $HADOOP_HOME/share/hadoop/mapreduce/</li>

<li><p>Edit mapred-site.xml in $HADOOP_HOME/etc/hadoop, add java opts settings for map-collective tasks. For example:</p>
<property>
<name>mapreduce.map.collective.memory.mb</name>
<value>512</value>
</property>
<property>
<name>mapreduce.map.collective.java.opts</name>
<value>-Xmx256m -Xms256m</value>
</property></li>

<li><p>To develop Harp applications, remember to add the following property in job configuration:</p>
jobConf.set("mapreduce.framework.name", "map-collective");</li>
</ol>

<h2 id="step-3-run-harp-kmeans-example">Step 3 Run harp kmeans example</h2>

<ol>
<li><p>Format datanode in other nodes.</p>
$ ssh ${other nodes}
$ hadoop datanode -format

<p>You have to do this step in every node except the namenode.</p></li>

<li><p>Copy harp examples to <code>$HADOOP_HOME</code>.</p>
$ cp harp-app/target/harp-app-1.0-SNAPSHOT.jar $HADOOP_HOME</li>

<li><p>Start Hadoop.</p>
$ cd $HADOOP_HOME
$ sbin/start-dfs.sh
$ sbin/start-yarn.sh</li>

<li><p>Check and see if other nodes work as well. This output will only appear in datanode.</p>
$ jps
xxxxx DataNode
xxxxx NodeManager
xxxxx Jps</li>

<li><p>To view your running applications in terminal, use:</p>
$ yarn application -list</li>

<li><p>To shutdown a running application, use:</p>
$ yarn application -kill application-id</li>

<li><p>Run Kmeans Map-collective job. The usage is:</p>
$ hadoop jar harp-app-1.0-SNAPSHOT.jar edu.iu.kmeans.regroupallgather.KMeansLauncher <num of points> <num of centroids> <vector size> <num of point files per worker> <number of map tasks> <num threads> <number of iteration> <work dir> <local points dir>
#e.g. hadoop jar harp-app-1.0-SNAPSHOT.jar edu.iu.kmeans.regroupallgather.KMeansLauncher 1000 10 100 5 2 2 10 /kmeans /tmp/kmeans

<ul>
<li><code>&lt;num of points&gt;</code> &mdash; the number of data points you want to generate randomly</li>
<li><code>&lt;num of centriods&gt;</code> &mdash; the number of centroids you want to clustering the data to</li>
<li><code>&lt;vector size&gt;</code> &mdash; the number of dimension of the data</li>
<li><code>&lt;num of point files per worker&gt;</code> &mdash; how many files which contain data points in each worker</li>
<li><code>&lt;number of map tasks&gt;</code> &mdash; number of map tasks</li>
<li><code>&lt;num threads&gt;</code> &mdash; how many threads to launch in each worker</li>
<li><code>&lt;number of iteration&gt;</code> &mdash; the number of iterations to run</li>
<li><code>&lt;work dir&gt;</code> &mdash; the root directory for this running in HDFS</li>
<li><code>&lt;local points dir&gt;</code> &mdash; the harp kmeans will firstly generate files which contain data points to local directory. Set this argument to determine the local directory.</li>
</ul></li>

<li><p>To fetch the results, use the following command:</p>
$ hdfs dfs –get <work dir> <local dir>
#e.g. hdfs dfs -get /kmeans ~/Document</li>
</ol>
</article></section></div></div></div><script src="https://code.jquery.com/jquery-2.2.1.min.js"></script><script src="https://dsc-spidal.github.io/harp/js/app.min.js"></script></body></html>