
@article{mitchell_accelerating_2017,
	title = {Accelerating the {XGBoost} algorithm using {GPU} computing},
	volume = {5},
	url = {https://peerj.com/preprints/2911},
	urldate = {2017-09-18},
	journal = {PeerJ Preprints},
	author = {Mitchell, Rory and Frank, Eibe},
	year = {2017},
	pages = {e2911v1},
	file = {Mitchell_Frank_2017_Accelerating the XGBoost algorithm using GPU computing.pdf:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/QKQTI9IZ/Mitchell_Frank_2017_Accelerating the XGBoost algorithm using GPU computing.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/BURMMK5U/2911.html:text/html}
}

@inproceedings{chen_xgboost:_2016,
	title = {Xgboost: {A} scalable tree boosting system},
	shorttitle = {Xgboost},
	url = {http://dl.acm.org/citation.cfm?id=2939785},
	urldate = {2017-09-18},
	booktitle = {Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining},
	publisher = {ACM},
	author = {Chen, Tianqi and Guestrin, Carlos},
	year = {2016},
	pages = {785--794},
	file = {Chen_Guestrin_2016_Xgboost.pdf:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/JWDP95VR/Chen_Guestrin_2016_Xgboost.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/34XRFXHF/citation.html:text/html}
}

@article{friedman_greedy_2001,
	title = {Greedy function approximation: a gradient boosting machine},
	shorttitle = {Greedy function approximation},
	url = {http://www.jstor.org/stable/2699986},
	urldate = {2017-09-19},
	journal = {Annals of statistics},
	author = {Friedman, Jerome H.},
	year = {2001},
	pages = {1189--1232},
	file = {Friedman_2001_Greedy function approximation.pdf:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/H8DMDEFJ/Friedman_2001_Greedy function approximation.pdf:application/pdf}
}

@incollection{ke_lightgbm:_2017,
	title = {{LightGBM}: {A} {Highly} {Efficient} {Gradient} {Boosting} {Decision} {Tree}},
	shorttitle = {{LightGBM}},
	url = {http://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf},
	urldate = {2018-01-16},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30},
	publisher = {Curran Associates, Inc.},
	author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
	editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
	pages = {3149--3157},
	file = {NIPS Full Text PDF:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/NATA4995/Ke et al. - 2017 - LightGBM A Highly Efficient Gradient Boosting Dec.pdf:application/pdf;NIPS Snapshort:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/PAZWI8YQ/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.html:text/html}
}

@inproceedings{si_gradient_2017,
	title = {Gradient {Boosted} {Decision} {Trees} for {High} {Dimensional} {Sparse} {Output}},
	url = {http://proceedings.mlr.press/v70/si17a.html},
	abstract = {In this paper, we study the gradient boosted decision trees (GBDT) when the output space is high dimensional and sparse. For example, in multilabel classification, the output space is a \$L\$-dimensi...},
	language = {en},
	urldate = {2018-01-16},
	booktitle = {{PMLR}},
	author = {Si, Si and Zhang, Huan and Keerthi, S. Sathiya and Mahajan, Dhruv and Dhillon, Inderjit S. and Hsieh, Cho-Jui},
	month = jul,
	year = {2017},
	pages = {3182--3190},
	file = {Full Text PDF:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/UCJJEISA/Si et al. - 2017 - Gradient Boosted Decision Trees for High Dimension.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/ZMN73RQC/si17a.html:text/html}
}

@inproceedings{jiang_tencentboost:_2017,
	title = {{TencentBoost}: {A} {Gradient} {Boosting} {Tree} {System} with {Parameter} {Server}},
	shorttitle = {{TencentBoost}},
	doi = {10.1109/ICDE.2017.87},
	abstract = {Gradient boosting tree (GBT), a widely used machine learning algorithm, achieves state-of-the-art performance in academia, industry, and data analytics competitions. Although existing scalable systems which implement GBT, such as XGBoost and MLlib, perform well for datasets with medium-dimensional features, they can suffer performance degradation for many industrial applications where the trained datasets contain highdimensional features. The performance degradation derives from their inefficient mechanisms for model aggregation-either mapreduce or all-reduce. To address this high-dimensional problem, we propose a scalable execution plan using the parameter server architecture to facilitate the model aggregation. Further, we introduce a sparse-pull method and an efficient index structure to increase the processing speed. We implement a GBT system, namely TencentBoost, in the production cluster of Tencent Inc. The empirical results show that our system is 2-20Ã— faster than existing platforms.},
	booktitle = {2017 {IEEE} 33rd {International} {Conference} on {Data} {Engineering} ({ICDE})},
	author = {Jiang, J. and Jiang, J. and Cui, B. and Zhang, C.},
	month = apr,
	year = {2017},
	keywords = {Computer architecture, workstation clusters, learning (artificial intelligence), Training, Boosting, Buildings, data analytics, file servers, GBT, GBT system, gradient boosting tree system, high-dimensional features, Histograms, index structure, Indexes, machine learning algorithm, medium-dimensional features, model aggregation, parameter server architecture, performance degradation, Servers, sparse-pull method, TencentBoost},
	pages = {281--284},
	file = {IEEE Xplore Abstract Record:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/ZWBHELEM/7929984.html:text/html;IEEE Xplore Full Text PDF:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/V354WBF2/Jiang et al. - 2017 - TencentBoost A Gradient Boosting Tree System with.pdf:application/pdf}
}

@inproceedings{ponomareva_tf_2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{TF} {Boosted} {Trees}: {A} {Scalable} {TensorFlow} {Based} {Framework} for {Gradient} {Boosting}},
	isbn = {978-3-319-71272-7 978-3-319-71273-4},
	shorttitle = {{TF} {Boosted} {Trees}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-71273-4_44},
	doi = {10.1007/978-3-319-71273-4_44},
	abstract = {TF Boosted Trees (TFBT) is a new open-sourced framework for the distributed training of gradient boosted trees. It is based on TensorFlow, and its distinguishing features include a novel architecture, automatic loss differentiation, layer-by-layer boosting that results in smaller ensembles and faster prediction, principled multi-class handling, and a number of regularization techniques to prevent overfitting.},
	language = {en},
	urldate = {2018-01-16},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer, Cham},
	author = {Ponomareva, Natalia and Radpour, Soroush and Hendry, Gilbert and Haykal, Salem and Colthurst, Thomas and Mitrichev, Petr and Grushetsky, Alexander},
	month = sep,
	year = {2017},
	pages = {423--427},
	file = {Full Text PDF:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/2276TLNJ/Ponomareva et al. - 2017 - TF Boosted Trees A Scalable TensorFlow Based Fram.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/TY67WPNR/978-3-319-71273-4_44.html:text/html}
}

@inproceedings{ponomareva_compact_2017,
	title = {Compact multi-class boosted trees},
	doi = {10.1109/BigData.2017.8257910},
	abstract = {Gradient boosted decision trees are a popular machine learning technique, in part because of their ability to give good accuracy with small models. We describe two extensions to the standard tree boosting algorithm designed to increase this advantage. The first improvement extends the boosting formalism from scalar-valued trees to vector-valued trees. This allows individual trees to be used as multiclass classifiers, rather than requiring one tree per class, and drastically reduces the model size required for multiclass problems. We also show that some other popular vector-valued gradient boosted trees modifications fit into this formulation and can be easily obtained in our implementation. The second extension, layer-by-layer boosting, takes smaller steps in function space, which is empirically shown to lead to a faster convergence and to a more compact ensemble. We have added both improvements to the open-source TensorFlow Boosted trees (TFBT) package, and we demonstrate their efficacy on a variety of multiclass datasets. We expect these extensions will be of particular interest to boosted tree applications that require small models, such as embedded devices, applications requiring fast inference, or applications desiring more interpretable models.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Ponomareva, N. and Colthurst, T. and Hendry, G. and Haykal, S. and Radpour, S.},
	month = dec,
	year = {2017},
	keywords = {learning (artificial intelligence), Logistics, Mathematical model, large-scale machine learning, Encoding, pattern classification, Boosting, boosted tree applications, boosting formalism, compact ensemble, compact multiclass boosted trees, Convergence, decision trees, Decision trees, ensemble methods, gradient boosted trees modifications, gradient methods, interpretable models, layer-by-layer boosting, machine learning technique, model size, multiclass classifiers, multiclass datasets, Multiclass gradient boosting, open-source TensorFlow Boosted trees package, scalar-valued trees, standard tree boosting algorithm, TensorFlow, tree-based methods, vector-valued trees, Vegetation},
	pages = {47--56},
	file = {IEEE Xplore Abstract Record:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/5LF7U73U/8257910.html:text/html;IEEE Xplore Full Text PDF:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/IKFMCJAP/Ponomareva et al. - 2017 - Compact multi-class boosted trees.pdf:application/pdf}
}

@article{friedman_additive_2000,
	title = {Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors)},
	volume = {28},
	shorttitle = {Additive logistic regression},
	number = {2},
	journal = {The annals of statistics},
	author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
	year = {2000},
	pages = {337--407},
	file = {Fulltext:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/NRUNEWE8/Friedman et al. - 2000 - Additive logistic regression a statistical view o.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/GCMQ2XBG/1016218223.html:text/html}
}

@article{friedman_greedy_2001-1,
	title = {Greedy function approximation: a gradient boosting machine},
	shorttitle = {Greedy function approximation},
	journal = {Annals of statistics},
	author = {Friedman, Jerome H.},
	year = {2001},
	pages = {1189--1232},
	file = {Friedman - 2001 - Greedy function approximation a gradient boosting.pdf:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/88C3HRWX/Friedman - 2001 - Greedy function approximation a gradient boosting.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/3E7R9Y6T/2699986.html:text/html}
}

@article{panda_planet:_2009,
	title = {Planet: massively parallel learning of tree ensembles with mapreduce},
	volume = {2},
	shorttitle = {Planet},
	number = {2},
	journal = {Proceedings of the VLDB Endowment},
	author = {Panda, Biswanath and Herbach, Joshua S. and Basu, Sugato and Bayardo, Roberto J.},
	year = {2009},
	pages = {1426--1437},
	file = {Fulltext:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/I2S9Y4QP/Panda et al. - 2009 - Planet massively parallel learning of tree ensemb.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/NQGZCWAG/citation.html:text/html}
}

@inproceedings{tyree_parallel_2011,
	title = {Parallel boosted regression trees for web search ranking},
	booktitle = {Proceedings of the 20th international conference on {World} wide web},
	publisher = {ACM},
	author = {Tyree, Stephen and Weinberger, Kilian Q. and Agrawal, Kunal and Paykin, Jennifer},
	year = {2011},
	pages = {387--396},
	file = {Fulltext:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/AALMAVT3/Tyree et al. - 2011 - Parallel boosted regression trees for web search r.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/73W5493Q/citation.html:text/html}
}

@inproceedings{ye_stochastic_2009,
	title = {Stochastic gradient boosted distributed decision trees},
	booktitle = {Proceedings of the 18th {ACM} conference on {Information} and knowledge management},
	publisher = {ACM},
	author = {Ye, Jerry and Chow, Jyh-Herng and Chen, Jiang and Zheng, Zhaohui},
	year = {2009},
	pages = {2061--2064},
	file = {Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/Z5QCHKQV/citation.html:text/html}
}

@inproceedings{jiang_dimboost:_2018,
	title = {{DimBoost}: {Boosting} {Gradient} {Boosting} {Decision} {Tree} to {Higher} {Dimensions}},
	shorttitle = {{DimBoost}},
	booktitle = {Proceedings of the 2018 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Jiang, Jiawei and Cui, Bin and Zhang, Ce and Fu, Fangcheng},
	year = {2018},
	pages = {1363--1376},
	file = {Jiang et al. - 2018 - DimBoost Boosting Gradient Boosting Decision Tree.pdf:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/DR58CJ3B/Jiang et al. - 2018 - DimBoost Boosting Gradient Boosting Decision Tree.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/HYLENFQM/citation.html:text/html}
}

@inproceedings{mohan_web-search_2011,
	title = {Web-search ranking with initialized gradient boosted regression trees},
	booktitle = {Proceedings of the learning to rank challenge},
	author = {Mohan, Ananth and Chen, Zheng and Weinberger, Kilian},
	year = {2011},
	pages = {77--89},
	file = {Fulltext:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/EFSWCU65/Mohan et al. - 2011 - Web-search ranking with initialized gradient boost.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/US6U5AVW/Mohan et al. - 2011 - Web-search ranking with initialized gradient boost.pdf:application/pdf}
}

@article{ben-haim_streaming_2010,
	title = {A streaming parallel decision tree algorithm},
	volume = {11},
	number = {Feb},
	journal = {Journal of Machine Learning Research},
	author = {Ben-Haim, Yael and Tom-Tov, Elad},
	year = {2010},
	pages = {849--872},
	file = {Fulltext:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/9M5UWJU2/Ben-Haim and Tom-Tov - 2010 - A streaming parallel decision tree algorithm.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/8KI7NMW7/ben-haim10a.html:text/html}
}

@inproceedings{zheng_general_2008,
	title = {A general boosting method and its application to learning ranking functions for web search},
	booktitle = {Advances in neural information processing systems},
	author = {Zheng, Zhaohui and Zha, Hongyuan and Zhang, Tong and Chapelle, Olivier and Chen, Keke and Sun, Gordon},
	year = {2008},
	pages = {1697--1704},
	file = {Fulltext:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/4T67EIK3/Zheng et al. - 2008 - A general boosting method and its application to l.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/8XMKATWQ/3305-a-general-boosting-method-and-its-application-to-learning-ranking-functions-for-web-search.html:text/html}
}

@inproceedings{ye_stochastic_2009-1,
	title = {Stochastic gradient boosted distributed decision trees},
	booktitle = {Proceedings of the 18th {ACM} conference on {Information} and knowledge management},
	publisher = {ACM},
	author = {Ye, Jerry and Chow, Jyh-Herng and Chen, Jiang and Zheng, Zhaohui},
	year = {2009},
	pages = {2061--2064},
	file = {Fulltext:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/PWVF3HCV/Ye et al. - 2009 - Stochastic gradient boosted distributed decision t.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/V2YFU92Q/citation.html:text/html}
}

@article{zhou_deep_2017,
	title = {Deep forest: {Towards} an alternative to deep neural networks},
	shorttitle = {Deep forest},
	journal = {arXiv preprint arXiv:1702.08835},
	author = {Zhou, Zhi-Hua and Feng, Ji},
	year = {2017},
	file = {Fulltext:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/4ZEJXX7T/Zhou and Feng - 2017 - Deep forest Towards an alternative to deep neural.pdf:application/pdf;Snapshot:/home/pb/.mozilla/firefox/97ife9q7.default/zotero/storage/FZG5YW53/1702.html:text/html}
}