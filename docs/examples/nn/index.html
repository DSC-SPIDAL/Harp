<!DOCTYPE html><html lang="en-us"><head><link rel="shortcut icon" type="image/png" sizes="16x16" href="https://dsc-spidal.github.io/harp/img/favicon-16x9.png"><link rel="shortcut icon" type="image/png" sizes="32x32" href="https://dsc-spidal.github.io/harp/img/favicon-32x18.png"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Hugo 0.16-DEV" /><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="harp"><meta property="og:image" content="/img/logo54x54.png"><meta property="og:url" content="https://dsc-spidal.github.io/harp/"><meta name="twitter:title" content="harp"><meta name="twitter:image" content=""><meta property="og:site_name" content="Harp Neural Network"><meta property="og:url" content=""><meta property="og:description" content=""><meta name="twitter:description" content=""><title>harp Documentation - Harp Neural Network</title><link rel="stylesheet" href="https://dsc-spidal.github.io/harp/css/style.min.css"><link rel="stylesheet" href="https://dsc-spidal.github.io/harp/css/font-awesome.min.css"><link rel="stylesheet" href="https://dsc-spidal.github.io/harp/css/pygments.css"></head><body><nav class="hn-top-navbar navbar navbar-inverse navbar-fixed-top" role="navigation"><div class="hn-navbar-container container-fluid"><div class="navbar-header"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#hn-navbar" aria-controls="hn-navbar" aria-expanded="false"><span class="sr-only"><Toggle>navigation</Toggle></span><i class="hn-toggle-button fa fa-bars"></i></button><a class="hn-navbar-logo navbar-brand" href="https://dsc-spidal.github.io/harp/"><img class="pull-left" src="https://dsc-spidal.github.io/harp/img/0-1-2.png" width="76%"></a></div><div id="hn-navbar" class="navbar-collapse collapse"><ul class="nav navbar-nav navbar-right"><li><a href="https://dsc-spidal.github.io/harp/docs/getting-started">Documentation</a></li><li><a href="https://dsc-spidal.github.io/harp/api">API</a></li></ul></div></div></nav><div class="hn-main"><div class="container"><div class="row"><aside class="hn-sidebar hidden-xs col-sm-4 col-md-3 col-lg-2 collapse"><nav class="hn-sidebar-nav"><div id="hn-accordion-1" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="installation-guide" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-1" href="#collapse-installation-guide" aria-labelledby="installation-guide"><i class="fa fa-caret-right"></i>Installation Guide</a></h4></section><div id="collapse-installation-guide" class="panel-collapse collapse" aria-labelledby="installation-guide"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/prerequisites">Prerequisites</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/getting-started">Harp Installation (Single Node)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/getting-started-cluster">Harp Installation (Cluster)</a></li></ul></div></div></div></div></nav><h2 class="panel-title"><b>Users Guide</b></h2><br><nav class="hn-sidebar-nav"><div id="hn-accordion-2" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="applications" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-2" href="#collapse-applications" aria-labelledby="applications"><i class="fa fa-caret-right"></i>Applications</a></h4></section><div id="collapse-applications" class="panel-collapse collapse" aria-labelledby="applications"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/applications/lda-cgs">Latent Dirichlet Allocation (CGS)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/applications/mf">Matrix Factorization</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/applications/sahad">Subgraph Counting</a></li></ul></div></div></div></div></nav><h2 class="panel-title"><b>Contributors Guide</b></h2><br><nav class="hn-sidebar-nav"><div id="hn-accordion-3" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="programming-guides" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-3" href="#collapse-programming-guides" aria-labelledby="programming-guides"><i class="fa fa-caret-right"></i>Programming Guides</a></h4></section><div id="collapse-programming-guides" class="panel-collapse collapse" aria-labelledby="programming-guides"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/programming/overview">Overview</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/programming/data-interface">Data Interfaces and Types</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/programming/scheduler">Schedulers</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/programming/computation-models">Computation Models</a></li></ul></div></div></div><div class="panel panel-default"><section id="collective-communication" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-3" href="#collapse-collective-communication" aria-labelledby="collective-communication"><i class="fa fa-caret-right"></i>Collective Communication</a></h4></section><div id="collapse-collective-communication" class="panel-collapse collapse" aria-labelledby="collective-communication"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/communications/broadcast">Broadcast</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/reduce">Reduce</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/allgather">Allgather</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/allreduce">Allreduce</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/regroup">Regroup</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/pushandpull">Push &amp; Pull</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/rotate">Rotate</a></li></ul></div></div></div><div class="panel panel-default"><section id="examples" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-3" href="#collapse-examples" aria-labelledby="examples"><i class="fa fa-caret-right"></i>Examples</a></h4></section><div id="collapse-examples" class="panel-collapse collapse" aria-labelledby="examples"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/examples/overview">Overview</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/kmeans">K-Means</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/mlrsgd">Multiclass Logistic Regression</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/lda">Latent Dirichlet Allocation (CVB)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/svm">Support Vector Machine</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/rf">Random Forests</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/nn">Neural Network</a></li></ul></div></div></div></div></nav><h2 class="panel-title"><b>Harp-DAAL Documentation</b></h2><br><nav class="hn-sidebar-nav"><div id="hn-accordion-4" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="overview" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-4" href="#collapse-overview" aria-labelledby="overview"><i class="fa fa-caret-right"></i>Overview</a></h4></section><div id="collapse-overview" class="panel-collapse collapse" aria-labelledby="overview"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/harpdaal">Harp-DAAL framework</a></li></ul></div></div></div><div class="panel panel-default"><section id="algorithms" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-4" href="#collapse-algorithms" aria-labelledby="algorithms"><i class="fa fa-caret-right"></i>Algorithms</a></h4></section><div id="collapse-algorithms" class="panel-collapse collapse" aria-labelledby="algorithms"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/kmeans">K-means</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/mfsgd">Matrix Factorization (SGD)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/als">Recommender System (ALS)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/svd">Singular Value Decomposition (SVD)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/pca">Principal Component Analysis (PCA)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/nn">Neural Network</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/qr">QR Decomposition (QR)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/covariance">Covariance</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/moments">Low Order Moments</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/naive_bayes">Naive Bayes</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/linear_regression">Linear Regression</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/ridge_regression">Ridge Regression</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/subgraph">Subgraph Counting</a></li></ul></div></div></div><div class="panel panel-default"><section id="hands-on" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-4" href="#collapse-hands-on" aria-labelledby="hands-on"><i class="fa fa-caret-right"></i>Hands-on</a></h4></section><div id="collapse-hands-on" class="panel-collapse collapse" aria-labelledby="hands-on"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/handson">Tutorial</a></li></ul></div></div></div></div></nav></aside><section class="hn-docs-main col-sm-8 col-md-9 col-lg-10 col-sm-offset-4 col-md-offset-3 col-lg-offset-2"><header class="hn-docs-header page-header"><h1>Harp Neural Network</h1><div class="hn-docs-description"></div></header><article class="hn-docs-content">

<p>Before going through this tutorial take a look at the <a href="https://dsc-spidal.github.io/harp/docs/examples/overview/">overview</a> section.</p>

<p><img src="https://dsc-spidal.github.io/harp/img/nn.png" width="60%"  ></p>

<p>Neural networks are a set of algorithms, which is based on a large of neural units. Each neural unit is connected with many others, and forms a network structure. Computation happens in the neural unit, which combines all the inputs with a set of coefficients, or weights, and gives an output by an activation function. A layer is a group of neural units, that each layer’s output is the subsequent layer’s input. A learning algorithm tries to learn the weights from data, and then the network can be used to recognize patterns.</p>

<p>Here, we give a simple tutorial on how to parallel a standard implementation of the <a href="https://en.wikipedia.org/wiki/Backpropagation">BP algorithm</a> for a feed-forward network.</p>

<h2 id="parallel-design:d53501e04079b53fe39a85cd37d15502">PARALLEL DESIGN</h2>

<ul>
<li><p>What is the model? What kind of data structure is applicable?</p>

<p>Weights matrices, including the biases for each node, between each adjacent layers are the model in neural network. It is a vector of double matrix.</p></li>

<li><p>What are the characteristics of the data dependency in model update computation? Can updates run concurrently?</p>

<p>In the core model update computation in BP training algorithm, each data point, or a minibatch, should access all the model, compute gradients and update model layer by layer from the output layer back to the input layer.</p>

<p>The nodes in the same layer can be updated in parallel without conflicts, but there are dependency between the layers. But generally, it is not easy to utilize these network structure related parallelism.</p></li>

<li><p>Which kind of parallelism scheme is suitable, data parallelism or model parallelism?</p>

<p>Data parallelism can be used, i.e., calculating different data points in parallel.</p>

<p>No model parallelism, each node get one replica of the whole model, which updates locally in parallel, and then synchronizes and averages when local computation all finish.</p></li>

<li><p>which collective communication operation is suitable to synchronize the model?</p>

<p>Synchronize replicas of the model by allreduce is an simple solution.</p></li>
</ul>

<h2 id="dataflow:d53501e04079b53fe39a85cd37d15502">DATAFLOW</h2>

<p><img src="https://dsc-spidal.github.io/harp/img/nn-dataflow.png" width="60%"  ></p>

<h2 id="step-1-set-table:d53501e04079b53fe39a85cd37d15502">Step 1 &mdash; Set Table</h2>

<p>The data format wrapper code is in charge of the conversion between the native DoubleMatrix and Harp Table.</p>
<div class="highlight" style="background: #272822"><pre style="line-height: 125%"><span></span><span style="color: #66d9ef">public</span> <span style="color: #f8f8f2">Table</span><span style="color: #f92672">&lt;</span><span style="color: #f8f8f2">DoubleArray</span><span style="color: #f92672">&gt;</span> <span style="color: #a6e22e">train</span><span style="color: #f92672">(</span><span style="color: #f8f8f2">DoubleMatrix</span> <span style="color: #f8f8f2">X</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">DoubleMatrix</span> <span style="color: #f8f8f2">Y</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">Table</span><span style="color: #f92672">&lt;</span><span style="color: #f8f8f2">DoubleArray</span><span style="color: #f92672">&gt;</span> <span style="color: #f8f8f2">localWeightTable</span><span style="color: #f92672">,</span> <span style="color: #66d9ef">int</span> <span style="color: #f8f8f2">mini_epochs</span><span style="color: #f92672">,</span> <span style="color: #66d9ef">int</span> <span style="color: #f8f8f2">numMapTasks</span><span style="color: #f92672">,</span> <span style="color: #66d9ef">double</span> <span style="color: #f8f8f2">lambda</span><span style="color: #f92672">)</span> <span style="color: #66d9ef">throws</span> <span style="color: #f8f8f2">IOException</span>
<span style="color: #f92672">{</span>
    <span style="color: #f8f8f2">Vector</span><span style="color: #f92672">&lt;</span><span style="color: #f8f8f2">DoubleMatrix</span><span style="color: #f92672">&gt;</span> <span style="color: #f8f8f2">weightMatrix</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">reshapeTableToList</span><span style="color: #f92672">(</span><span style="color: #f8f8f2">localWeightTable</span><span style="color: #f92672">);</span>
    <span style="color: #f8f8f2">setTheta</span><span style="color: #f92672">(</span><span style="color: #f8f8f2">weightMatrix</span><span style="color: #f92672">);</span>

    <span style="color: #f8f8f2">trainBP</span><span style="color: #f92672">(</span><span style="color: #f8f8f2">X</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">Y</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">lambda</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">mini_epochs</span><span style="color: #f92672">,</span> <span style="color: #66d9ef">true</span><span style="color: #f92672">);</span>

    <span style="color: #f8f8f2">Table</span><span style="color: #f92672">&lt;</span><span style="color: #f8f8f2">DoubleArray</span><span style="color: #f92672">&gt;</span> <span style="color: #f8f8f2">newWeightTable</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">reshapeListToTable</span><span style="color: #f92672">(</span><span style="color: #66d9ef">this</span><span style="color: #f92672">.</span><span style="color: #a6e22e">getTheta</span><span style="color: #f92672">());</span>
    <span style="color: #66d9ef">return</span> <span style="color: #f8f8f2">newWeightTable</span><span style="color: #f92672">;</span>
<span style="color: #f92672">}</span>
</pre></div>

<h2 id="step-2-communication:d53501e04079b53fe39a85cd37d15502">Step 2 &mdash;Communication</h2>

<p>The code snippet for the core part of computation in the iterative training. There  are only a few lines of differences between the harp distributed version and the original sequential version.</p>
<div class="highlight" style="background: #272822"><pre style="line-height: 125%"><span></span><span style="color: #75715e">// Calculate the new weights </span>
<span style="color: #75715e">// argument data type conversion and call the train() in the underlie library</span>
<span style="color: #f8f8f2">weightTable</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">localNN</span><span style="color: #f92672">.</span><span style="color: #a6e22e">train</span><span style="color: #f92672">(</span><span style="color: #f8f8f2">X</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">Y</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">weightTable</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">n</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">numMapTasks</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">lambda</span><span style="color: #f92672">);</span>

<span style="color: #75715e">// reduce and broadcast</span>
<span style="color: #f8f8f2">allreduce</span><span style="color: #f92672">(</span><span style="color: #e6db74">&quot;main&quot;</span><span style="color: #f92672">,</span> <span style="color: #e6db74">&quot;allreduce&quot;</span> <span style="color: #f92672">+</span> <span style="color: #f8f8f2">i</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">weightTable</span><span style="color: #f92672">);</span>

<span style="color: #75715e">// Average the weight table by the numMapTasks</span>
<span style="color: #f8f8f2">weightTable</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">localNN</span><span style="color: #f92672">.</span><span style="color: #a6e22e">modelAveraging</span><span style="color: #f92672">(</span><span style="color: #f8f8f2">weightTable</span><span style="color: #f92672">,</span> <span style="color: #f8f8f2">numMapTasks</span><span style="color: #f92672">);</span>
</pre></div>

<h1 id="data:d53501e04079b53fe39a85cd37d15502">DATA</h1>

<p>The <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> dataset is used in this tutorial.</p>

<h1 id="run-example:d53501e04079b53fe39a85cd37d15502">Run example</h1>

<h3 id="put-data-on-hdfs:d53501e04079b53fe39a85cd37d15502">Put data on hdfs</h3>
<div class="highlight" style="background: #272822"><pre style="line-height: 125%"><span></span>	<span style="color: #75715e">#download the dataset</span>
    python <span style="color: #f8f8f2">$HARP_ROOT_DIR</span>/datasets/tutorial/mnist/fetech_mnist.py
	<span style="color: #75715e">#split into 2 parts</span>
    python <span style="color: #f8f8f2">$HARP_ROOT_DIR</span>/datasets/tutorial/mnist/split_mnist.py mnist_data 2

    <span style="color: #75715e">#upload data to hadoop</span>
    hadoop fs -mkdir -p /nn/batch
    hadoop fs -put mnist_data_?.* /nn/batch
</pre></div>

<h3 id="compile:d53501e04079b53fe39a85cd37d15502">Compile</h3>

<p>Select the profile related to your hadoop version. For ex: hadoop-2.6.0. Supported hadoop versions are 2.6.0, 2.7.5
and 2.9.0</p>
<div class="highlight" style="background: #272822"><pre style="line-height: 125%"><span></span><span style="color: #f8f8f2">cd</span> <span style="color: #f8f8f2">$HARP_ROOT_DIR</span>
mvn clean package -Phadoop-2.6.0
</pre></div>
<div class="highlight" style="background: #272822"><pre style="line-height: 125%"><span></span><span style="color: #f8f8f2">cd</span> <span style="color: #f8f8f2">$HARP_ROOT_DIR</span>/contrib/target
cp contrib-0.1.0.jar <span style="color: #f8f8f2">$HADOOP_HOME</span>
cp <span style="color: #f8f8f2">$HARP_ROOT_DIR</span>/third_parity/jblas-1.2.4.jar <span style="color: #f8f8f2">$HADOOP_HOME</span>/share/hadoop/mapreduce
cp <span style="color: #f8f8f2">$HARP_ROOT_DIR</span>/third_parity/neuralNet-1.0.0-SNAPSHOT.jar <span style="color: #f8f8f2">$HADOOP_HOME</span>/share/hadoop/mapreduce
<span style="color: #f8f8f2">cd</span> <span style="color: #f8f8f2">$HADOOP_HOME</span>
</pre></div>

<h3 id="run:d53501e04079b53fe39a85cd37d15502">Run</h3>
<div class="highlight" style="background: #272822"><pre style="line-height: 125%"><span></span>hadoop jar contrib-0.1.0.jar edu.iu.NN.NNMapCollective
Usage: NNMapCollective &lt;number of map tasks&gt; &lt;epochs&gt; &lt;syncIterNum&gt; &lt;hiddenLayers&gt; &lt;minibatchsize&gt; &lt;lambda&gt; &lt;workDir&gt;
</pre></div>

<h3 id="example:d53501e04079b53fe39a85cd37d15502">Example</h3>
<div class="highlight" style="background: #272822"><pre style="line-height: 125%"><span></span>hadoop jar contrib-0.1.0.jar edu.iu.NN.NNMapCollective <span style="color: #ae81ff">2</span> <span style="color: #ae81ff">20</span> <span style="color: #ae81ff">5</span> 100,32 <span style="color: #ae81ff">2000</span> <span style="color: #ae81ff">0</span> /nn
</pre></div>

<p>This command run harp neuralnetwork training on the input dataset under /nn, with 2 mappers. Training process goes through 20 times of the training dataset, averages the model every 5 iteration for each minibatch. The minibatch size is 2000, lambda is default value 0.689. There are 2 hidden layers, with 100 and 32 nodes each. Finally, it outputs the accuracy on the training set into the hadoop log.</p>
</article></section></div></div></div><script src="https://code.jquery.com/jquery-2.2.1.min.js"></script><script src="https://dsc-spidal.github.io/harp/js/app.min.js"></script></body></html>