<!DOCTYPE html><html lang="en-us"><head><link rel="shortcut icon" type="image/png" sizes="16x16" href="https://dsc-spidal.github.io/harp/img/favicon-16x9.png"><link rel="shortcut icon" type="image/png" sizes="32x32" href="https://dsc-spidal.github.io/harp/img/favicon-32x18.png"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Hugo 0.18" /><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="harp"><meta property="og:image" content="/img/logo54x54.png"><meta property="og:url" content="https://dsc-spidal.github.io/harp/"><meta name="twitter:title" content="harp"><meta name="twitter:image" content="/img/0-1-1.png"><meta property="og:site_name" content="Algorithms in Harp-DAAL"><meta property="og:url" content="/docs/harpdaal/algorithms/"><meta property="og:description" content=""><meta name="twitter:description" content=""><title>harp Documentation - Algorithms in Harp-DAAL</title><link rel="stylesheet" href="https://dsc-spidal.github.io/harp/css/style.min.css"><link rel="stylesheet" href="https://dsc-spidal.github.io/harp/css/font-awesome.min.css"><link rel="stylesheet" href="https://dsc-spidal.github.io/harp/css/pygments.css"></head><body><nav class="hn-top-navbar navbar navbar-inverse navbar-fixed-top" role="navigation"><div class="hn-navbar-container container-fluid"><div class="navbar-header"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#hn-navbar" aria-controls="hn-navbar" aria-expanded="false"><span class="sr-only"><Toggle>navigation</Toggle></span><i class="hn-toggle-button fa fa-bars"></i></button><a class="hn-navbar-logo navbar-brand" href="https://dsc-spidal.github.io/harp/"><img class="pull-left" src="https://dsc-spidal.github.io/harp/img/0-1-2.png" width="76%"></a></div><div id="hn-navbar" class="navbar-collapse collapse"><ul class="nav navbar-nav navbar-right"><li><a href="https://dsc-spidal.github.io/harp/docs/getting-started">Documentation</a></li><li><a href="https://dsc-spidal.github.io/harp/api">API</a></li></ul></div></div></nav><div class="hn-main"><div class="container"><div class="row"><aside class="hn-sidebar hidden-xs col-sm-4 col-md-3 col-lg-2 collapse"><nav class="hn-sidebar-nav"><div id="hn-accordion-1" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="installation-guide" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-1" href="#collapse-installation-guide" aria-labelledby="installation-guide"><i class="fa fa-caret-right"></i>Installation Guide</a></h4></section><div id="collapse-installation-guide" class="panel-collapse collapse" aria-labelledby="installation-guide"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/prerequisites">Prerequisites</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/getting-started">Harp Installation (Single Node)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/getting-started-cluster">Harp Installation (Cluster)</a></li></ul></div></div></div></div></nav><nav class="hn-sidebar-nav"><div id="hn-accordion-2" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="beginners-guide" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-2" href="#collapse-beginners-guide" aria-labelledby="beginners-guide"><i class="fa fa-caret-right"></i>Beginners Guide</a></h4></section><div id="collapse-beginners-guide" class="panel-collapse collapse" aria-labelledby="beginners-guide"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/beginnersguide/mlr">Multiclass Logistic Regression</a></li></ul></div></div></div></div></nav><h2 class="panel-title"><b>Users Guide</b></h2><br><nav class="hn-sidebar-nav"><div id="hn-accordion-2" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="applications" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-2" href="#collapse-applications" aria-labelledby="applications"><i class="fa fa-caret-right"></i>Applications</a></h4></section><div id="collapse-applications" class="panel-collapse collapse" aria-labelledby="applications"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/applications/lda-cgs">Latent Dirichlet Allocation (CGS)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/applications/mf">Matrix Factorization</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/applications/sahad">Subgraph Counting</a></li></ul></div></div></div></div></nav><h2 class="panel-title"><b>Contributors Guide</b></h2><br><nav class="hn-sidebar-nav"><div id="hn-accordion-3" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="programming-guides" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-3" href="#collapse-programming-guides" aria-labelledby="programming-guides"><i class="fa fa-caret-right"></i>Programming Guides</a></h4></section><div id="collapse-programming-guides" class="panel-collapse collapse" aria-labelledby="programming-guides"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/programming/overview">Overview</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/programming/data-interface">Data Interfaces and Types</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/programming/scheduler">Schedulers</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/programming/computation-models">Computation Models</a></li></ul></div></div></div><div class="panel panel-default"><section id="collective-communication" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-3" href="#collapse-collective-communication" aria-labelledby="collective-communication"><i class="fa fa-caret-right"></i>Collective Communication</a></h4></section><div id="collapse-collective-communication" class="panel-collapse collapse" aria-labelledby="collective-communication"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/communications/broadcast">Broadcast</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/reduce">Reduce</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/allgather">Allgather</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/allreduce">Allreduce</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/regroup">Regroup</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/pushandpull">Push &amp; Pull</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/communications/rotate">Rotate</a></li></ul></div></div></div><div class="panel panel-default"><section id="examples" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-3" href="#collapse-examples" aria-labelledby="examples"><i class="fa fa-caret-right"></i>Examples</a></h4></section><div id="collapse-examples" class="panel-collapse collapse" aria-labelledby="examples"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/examples/overview">Overview</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/kmeans">K-Means</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/mlrsgd">Multiclass Logistic Regression</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/lda">Latent Dirichlet Allocation (CVB)</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/svm">Support Vector Machine</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/rf">Random Forests</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/examples/nn">Neural Network</a></li></ul></div></div></div></div></nav><h2 class="panel-title"><b>Harp-DAAL Documentation</b></h2><br><nav class="hn-sidebar-nav"><div id="hn-accordion-4" class="panel-group" role="tablist" aria-multiselectable="true"><div class="panel panel-default"><section id="overview" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-4" href="#collapse-overview" aria-labelledby="overview"><i class="fa fa-caret-right"></i>Overview</a></h4></section><div id="collapse-overview" class="panel-collapse collapse" aria-labelledby="overview"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/harpdaal">Harp-DAAL framework</a></li></ul></div></div></div><div class="panel panel-default"><section id="harp-daal-apis" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-4" href="#collapse-harp-daal-apis" aria-labelledby="harp-daal-apis"><i class="fa fa-caret-right"></i>Harp-DAAL APIs</a></h4></section><div id="collapse-harp-daal-apis" class="panel-collapse collapse" aria-labelledby="harp-daal-apis"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/harpdaalInit">Initialization Module</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/harpdaalIO">I/O Module</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/harpdaalComm">Communication Module</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/BatchModeEg">Batch Mode Code Walk Through</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/DistriModeEg">Distributed Mode Code Walk Through</a></li></ul></div></div></div><div class="panel panel-default"><section id="algorithms" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-4" href="#collapse-algorithms" aria-labelledby="algorithms"><i class="fa fa-caret-right"></i>Algorithms</a></h4></section><div id="collapse-algorithms" class="panel-collapse collapse" aria-labelledby="algorithms"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#arpos">Association Rule</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#covpos">Covariance</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#boostpos">Boosting</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#naivepos">Naive Bayes Classifier</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#kmeanspos">K-Means Clustering</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#empos">Expectation-Maximization</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#pcapos">Principal Component Analysis</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#svdpos">Singular Value Decomposition</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#qrpos">QR Decomposition</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#pqrpos">Pivoted-QR Decomposition</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#ckdpos">Cholesky Decomposition</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#mompos">Low Order Moments</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#odpos">Outlier Detection</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#sortpos">Sorting</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#qtepos">Quantile</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#qmpos">Quality Metrics</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#optpos">Optimization Solvers</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#normpos">Normalization</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#svmpos">Support Vector Machine</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#knnpos">K-Nearest Neighbors Classifier</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#dtreepos">Decision Tree</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#dforestpos">Decision Forest</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#kernelfuncpos">Kernel Functions</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#stumppos">Stump Weak Learner Classifier</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#linregpos">Linear Regression</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#reregpos">Ridge Regression</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#alspos">Implicit Alternating Least Squares</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/algorithms#nnpos">Neural Network</a></li></ul></div></div></div><div class="panel panel-default"><section id="algorithms-experimental" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-4" href="#collapse-algorithms-experimental" aria-labelledby="algorithms-experimental"><i class="fa fa-caret-right"></i>Algorithms Experimental</a></h4></section><div id="collapse-algorithms-experimental" class="panel-collapse collapse" aria-labelledby="algorithms-experimental"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/MF-SGD">Recommender System based on SGD</a></li><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/Subgraph">Subgraph Counting</a></li></ul></div></div></div><div class="panel panel-default"><section id="hands-on" class="panel-heading" role="tab"><h4 class="panel-title"><a role="button" data-toggle="collapse" data-parent="#hn-accordion-4" href="#collapse-hands-on" aria-labelledby="hands-on"><i class="fa fa-caret-right"></i>Hands-on</a></h4></section><div id="collapse-hands-on" class="panel-collapse collapse" aria-labelledby="hands-on"><div class="panel-body"><ul><li><a href="https://dsc-spidal.github.io/harp/docs/harpdaal/handson">Tutorial</a></li></ul></div></div></div></div></nav></aside><section class="hn-docs-main col-sm-8 col-md-9 col-lg-10 col-sm-offset-4 col-md-offset-3 col-lg-offset-2"><header class="hn-docs-header page-header"><h1>Algorithms in Harp-DAAL</h1><div class="hn-docs-description"></div></header><article class="hn-docs-content">

<p><a name="arpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="association-rule"><strong>Association Rule</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/association-rule-apriori.png" width="80%" ></p>

<p>Association rule learning is a rule-based learning method for discovering relations between variables in databases.
It is intended to identify strong rules discovered in databases using some measures of interestingness.</p>

<p>Harp-DAAL support a Batch mode of Association Rules based on the <em>Apriori</em> algorithm <sup class="footnote-ref" id="fnref:fn1"><a rel="footnote" href="#fn:fn1">1</a></sup>. provided by
More details from Intel DAAL kernel is found <a href="https://software.intel.com/en-us/daal-programming-guide-details-10">here</a></p>

<p><a name="covpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="covariance"><strong>Covariance</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/Covariance.png" width="80%" ></p>

<p>Covariance, in probability theory and statistics, is a measure of the joint variability of two random variables. The sign of the covariance
shows the tendency in the linear relationship between the variables. The correlation is the covariance normalized to be between -1 and +1.
A positive correlation indicates the extent to which variables increase or decrease simultaneously.
A negative correlation indicates the extent to which one variable increases while the other one decreases.</p>

<p>Harp-DAAL supports distributed modes of Covariance for both of dense and sparse (CSR format) input data.
Algorithmic details from Intel DAAL are found <a href="https://software.intel.com/en-us/daal-programming-guide-details-2">here</a></p>

<p><a name="boostpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="boosting"><strong>Boosting</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/boosting.png" width="80%" ></p>

<p>Boosting is a group of algorithms aiming to construct a strong classifier from a set of weighted weak classifiers
through iterative re-weighting based on accuracy measurement for weak classifiers. A weak classifier typically has only slightly better
performance than random guessing, which are very simple, fast, and focusing on specific feature classification.
Harp-DAAL supports batch modes of the following three boosting algorithms.</p>

<h3 id="adaboost-classifier">AdaBoost Classifier</h3>

<p>AdaBoost algorithm performs well on a variety of data sets except some noisy data <sup class="footnote-ref" id="fnref:fn2"><a rel="footnote" href="#fn:fn2">2</a></sup>.
More details are from <a href="https://software.intel.com/en-us/daal-programming-guide-details-29">Intel DAAL Documentation</a>
AdaBoost in Harp-DAAL is a binary classifier.</p>

<h3 id="brownboost-classifier">BrownBoost Classifier</h3>

<p>BrownBoost is a boosting classification algorithm. It is more robust to noisy data sets than other boosting classification algorithms.
More details are from <a href="https://software.intel.com/en-us/daal-programming-guide-details-30">Intel DAAL Documentation</a>
BrownBoost in Harp-DAAL is a binary classifier.</p>

<h3 id="logitboost-classifier">LogitBoost Classifier</h3>

<p>LogitBoost and AdaBoost are close to each other in the sense that both perform an additive logistic regression. The difference is that AdaBoost minimizes the exponential loss, whereas LogitBoost minimizes the logistic loss.</p>

<p>LogitBoost in Harp-DAAL is a multi-class classifier.
More details are from <a href="https://software.intel.com/en-us/daal-programming-guide-details-31">Intel DAAL Documentation</a></p>

<p><a name="naivepos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="naive-bayes-classifier"><strong>Naive Bayes Classifier</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/naive-bayes.png" width="80%" ></p>

<p>Naïve Bayes is a set of simple and powerful classification methods often used for text classification,
medical diagnosis, and other classification problems. In spite of their main assumption about independence between features,
Naïve Bayes classifiers often work well when this assumption does not hold.
An advantage of this method is that it requires only a small amount of training data to estimate model parameters.</p>

<p>Harp-DAAL currently supports distributed mode of Multinomial Naive Bayes <sup class="footnote-ref" id="fnref:fn3"><a rel="footnote" href="#fn:fn3">3</a></sup> for both of dense and sparse (CSR format) input datasets.
More details from Intel DAAL Documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-28">here</a></p>

<p><a name="kmeanspos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="k-means-clustering"><strong>K-means Clustering</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/kmeans-clustering.jpg" width="80%" ></p>

<p>K-means is a widely used clustering algorithm in machine learning community. It iteratively computes the distance between each
training point to every centroids, re-assigns the training point to new cluster and re-compute the new centroid of each cluster.
In other words, the clustering methods enable reducing the problem of analysis of the entire data set to the analysis of clusters.</p>

<p>Harp-DAAL currently supports distributed mode of K-means clustering for both of dense and sparse (CSR format)
input datasets.</p>

<p>More algorithmic details from Intel DAAL Documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-5">here</a>.</p>

<p><a name="empos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="expectation-maximization"><strong>Expectation Maximization</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/em.png" width="80%" ></p>

<p>Expectation-Maximization (EM) algorithm is an iterative method for finding the maximum likelihood and maximum a posteriori estimates of parameters in models that typically depend on hidden variables.</p>

<p>Harp-DAAL currently supports batch mode of EM <sup class="footnote-ref" id="fnref:fn4"><a rel="footnote" href="#fn:fn4">4</a></sup><sup class="footnote-ref" id="fnref:fn5"><a rel="footnote" href="#fn:fn5">5</a></sup> for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-13">here</a>.</p>

<p><a name="pcapos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="principle-component-analysis"><strong>Principle Component Analysis</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/pca.png" width="80%" ></p>

<p>Principle Component Analysis (PCA) is a widely used statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components (or sometimes, principal modes of variation).
PCA can be done by two methods:</p>

<ul>
<li>Eigenvalue decomposition of a data covariance (or cross-correlation)</li>
<li>Singular Value Decomposition of a data</li>
</ul>

<p>It is usually performed after normalizing (centering by the mean) the data matrix for each attribute.</p>

<p>In Harp-DAAL, we have two methods for computing PCA</p>

<h3 id="svd-based-pca">SVD Based PCA</h3>

<p>The input is a set of p-dimensional dense vectors, DAAL kernel invokes a SVD decomposition to find out $p_r$ principle directions (Eigenvectors)
The details of SVD kernel by Intel DAAL is <a href="https://software.intel.com/en-us/daal-programming-guide-singular-value-decomposition">here</a>.</p>

<p>Harp-DAAL provides distributed mode for SVD based PCA for dense input datasets.</p>

<h3 id="correleation-based-pca">Correleation Based PCA</h3>

<p>The input is a $p\tims p$ correlation matrix, and the DAAL PCA kernel will find out the $p_r$ directions <sup class="footnote-ref" id="fnref:fn6"><a rel="footnote" href="#fn:fn6">6</a></sup>.
Details from Intel DAAL Documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-6">here</a>.</p>

<p>Harp-DAAL provides distributed mode for Correlation based PCA for both of dense and sparse (CSR format) input datasets.</p>

<p><a name="svdpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="single-value-decomposition"><strong>Single Value Decomposition</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/SVD.png" width="80%" ></p>

<p>Singular Value Decomposition is a method which seeks to reduce the rank of a data matrix, thus finding the unique vectors, features, or characteristics of the data matrix at hand. This algorithm has been used in, but is not limited to signal processing, weather prediction, hotspot detection, and recommender systems.</p>

<p>Harp-DAAL currently supports the distributed mode for dense input datasets</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-9">here</a>.</p>

<p><a name="qrpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="qr-decomposition"><strong>QR Decomposition</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/QR.png" width="80%" ></p>

<p>The QR decomposition or QR factorization of a matrix is a decomposition of the matrix into an orthogonal matrix and a triangular matrix. A QR decomposition of a real square matrix A is a decomposition of A as A = QR, where Q is an orthogonal matrix (its columns are orthogonal unit vectors meaning Q<sup>T</sup>Q = I)
and R is an upper triangular matrix (also called right triangular matrix).</p>

<p>Harp-DAAL currently supports distributed mode of QR for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-11">here</a>.</p>

<p><a name="pqrpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="pivoted-qr-decomposition"><strong>Pivoted QR Decomposition</strong></h2>

<p>QR decomposition with column pivoting introduces a permutation matrix P and convert the original
<em>A=QR</em> to <em>AP=QR</em>. Column pivoting is useful when A is (nearly) rank deficient, or is suspected of being so. It can also improve numerical accuracy.</p>

<p>Harp-DAAL currently supports distributed mode of Pivoted QR for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-12">here</a>.</p>

<p><a name="ckdpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="cholesky-decomposition"><strong>Cholesky Decomposition</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/cholesky-decomposition.png" width="80%" ></p>

<p>Cholesky decomposition is a matrix factorization technique that decomposes a symmetric positive-definite matrix into a product of a lower triangular matrix and its conjugate transpose.</p>

<p>Harp-DAAL currently supports batch mode of Cholesky for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-8">here</a>.</p>

<p><a name="mompos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="moments-of-low-order"><strong>Moments of Low Order</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/low-order-moments.png" width="80%" ></p>

<p>Moments are basic quantitative measures of data set characteristics such as location and dispersion.
We compute the following low order characteristics: minimums/maximums, sums, means, sums of squares, sums of squared differences from the means, second order raw moments, variances, standard deviations, and variations.</p>

<p>Harp-DAAL supports the distributed mode of Low-order moments for both of dense and sparse (CSR format) input datasets</p>

<p>More algorithmic details from Intel DAAL documentation is found <a href="https://software.intel.com/en-us/daal-programming-guide-details">here</a>.</p>

<p><a name="odpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="outlier-detection"><strong>Outlier Detection</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/outlier-detection.png" width="80%" ></p>

<p>Outlier detection methods aim to identify observation points that are abnormally distant from other observation points.</p>

<h3 id="univariate">Univariate</h3>

<p>A univariate outlier is an occurrence of an abnormal value within a single observation point.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-16">here</a>.</p>

<h3 id="multivariate">Multivariate</h3>

<p>In multivariate outlier detection methods, the observation point is the entire feature vector.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-14">here</a>.</p>

<p>Harp-DAAL currently supports batch mode of outlier detection for dense input datasets.</p>

<p><a name="sortpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="sorting"><strong>Sorting</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/sorting.png" width="80%" ></p>

<p>Sorting is an algorithm to sort the observations by each feature (column) in the ascending order.</p>

<p>Harp-DAAL currently supports batch mode of sorting for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-17">here</a>.</p>

<p><a name="qtepos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="quantile"><strong>Quantile</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/quantile.png" width="80%" ></p>

<p>Quantile is an algorithm to analyze the distribution of observations. Quantiles are the values that divide the distribution so that a given portion of observations is below the quantile.</p>

<p>Harp-DAAL currently supports batch mode of Quantile for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-1">here</a>.</p>

<p><a name="qmpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="quality-metrics"><strong>Quality Metrics</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/quality-metrics.png" width="80%" ></p>

<p>A quality metric is a numerical characteristic or a set of connected numerical characteristics that represents
the qualitative aspect of the result returned by an algorithm: a computed statistical estimate, model, or result of decision making.</p>

<p>Harp-DAAL currently supports batch mode of sorting for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-quality-metrics">here</a>.</p>

<p><a name="optpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="optimization-solvers"><strong>Optimization Solvers</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/sgd-optimization.png" width="80%" ></p>

<p>An optimization solver is an algorithm to solve an optimization problem, which is to find the maximum or minimum of an
objective function in the presence of constraints on its variables.</p>

<p>Harp-DAAL currently provides the following iterative optimization solvers</p>

<h3 id="adaptive-subgradient-method">Adaptive Subgradient Method</h3>

<p>The adaptive subgradient method (AdaGrad) is from <sup class="footnote-ref" id="fnref:fn7"><a rel="footnote" href="#fn:fn7">7</a></sup>.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-adaptive-subgradient-method">here</a>.</p>

<h3 id="limited-memory-broyden-fletcher-goldfarb-shanno-algorithm">Limited-Memory Broyden-Fletcher-Goldfarb-Shanno Algorithm</h3>

<p>The limited-memory Broyden-Fletcher-Goldfarb-Shanno (LBFGS) algorithm is from <sup class="footnote-ref" id="fnref:fn8"><a rel="footnote" href="#fn:fn8">8</a></sup>.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-limited-memory-broyden-fletcher-goldfarb-shanno-algorithm">here</a>.</p>

<h3 id="stochastic-gradient-descent-algorithm">Stochastic Gradient Descent Algorithm</h3>

<p>The stochastic gradient descent (SGD) algorithm is a special case of an iterative solver.
The following computation methods are available in Intel DAAL for the stochastic gradient descent algorithm:</p>

<h4 id="mini-batch">Mini-batch.</h4>

<p>The mini-batch method (miniBatch) of the stochastic gradient descent algorithm is from <sup class="footnote-ref" id="fnref:fn9"><a rel="footnote" href="#fn:fn9">9</a></sup>.</p>

<h4 id="momentum">Momentum</h4>

<p>The momentum method (momentum) of the stochastic gradient descent algorithm is from <sup class="footnote-ref" id="fnref:fn10"><a rel="footnote" href="#fn:fn10">10</a></sup>.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-stochastic-gradient-descent-algorithm">here</a>.</p>

<p><a name="normpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="normalization"><strong>Normalization</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/normalization.png" width="80%" ></p>

<p>In statistics and applications of statistics, normalization can have a range of meanings.
In the simplest cases, normalization of ratings means adjusting values measured on different scales to a notionally common scale, often prior to averaging.
In more complicated cases, normalization may refer to more sophisticated adjustments where the intention is to bring the entire probability distributions of adjusted values into alignment.</p>

<p>Harp-DAAL currently supports batch mode of normalization for dense input datasets, and it
provides two algorithm kernels.</p>

<h3 id="min-max">Min-max</h3>

<p>Min-max normalization is an algorithm to linearly scale the observations by each feature (column) into the range [a, b].</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-min-max">here</a>.</p>

<h3 id="z-score">Z-score</h3>

<p>Z-score normalization is an algorithm to normalize the observations by each feature (column).</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-z-score">here</a>.</p>

<p><a name="svmpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="support-vector-machine-classifier"><strong>Support Vector Machine Classifier</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/svm.jpeg" width="80%" ></p>

<p>Support Vector Machine (SVM) is among popular classification algorithms.
It belongs to a family of generalized linear classification problems.
Because SVM covers binary classification problems only in the multi-class case, SVM must be used in conjunction with multi-class classifier methods.</p>

<p>Harp-DAAL currently supports batch mode of multi-class SVM <sup class="footnote-ref" id="fnref:fn11"><a rel="footnote" href="#fn:fn11">11</a></sup> for both of dense and sparse (CSR format) input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-32">here</a>.</p>

<p><a name="knnpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="k-nearest-neighbors-classifier"><strong>K-Nearest Neighbors Classifier</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/knn.png" width="80%" ></p>

<p>k-Nearest Neighbors (kNN) classification is a non-parametric classification algorithm. The model of the kNN classifier is based on feature vectors and class labels from the training data set. This classifier induces the class of the query vector from the labels of the feature vectors in the training data set to which the query vector is similar. A similarity between feature vectors is determined by the type of distance (for example, Euclidian) in a multidimensional feature space.</p>

<p>Harp-DAAL currently supports batch mode of K-NN <sup class="footnote-ref" id="fnref:fn12"><a rel="footnote" href="#fn:fn12">12</a></sup><sup class="footnote-ref" id="fnref:fn13"><a rel="footnote" href="#fn:fn13">13</a></sup> for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-34">here</a>.</p>

<p><a name="dtreepos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="decision-tree"><strong>Decision Tree</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/dtree.jpg" width="80%" ></p>

<p>Decision trees partition the feature space into a set of hypercubes, and then fit a simple model in each hypercube. The simple model can be a prediction model, which ignores all predictors and predicts the majority (most frequent) class (or the mean of a dependent variable for regression), also known as 0-R or constant classifier.</p>

<p>Harp-DAAL currently supports batch mode of Decision Tree for dense input datasets, which includes two sub-types</p>

<ul>
<li>Classification</li>
<li>Regression</li>
</ul>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-22">here</a>.</p>

<p><a name="dforestpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="decision-forest"><strong>Decision Forest</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/dforest.jpeg" width="80%" ></p>

<p>Decision forest classification and regression algorithms are based on an ensemble of tree-structured classifiers (decision trees)
built using the general technique of bootstrap aggregation (bagging) and random choice of features.</p>

<p>Harp-DAAL currently supports batch mode of Decision Forest for dense input datasets, which includes two sub-types</p>

<ul>
<li>Classification</li>
<li>Regression</li>
</ul>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-23">here</a>.</p>

<p><a name="kernelfuncpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="kernel-functions"><strong>Kernel Functions</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/kernel-function.png" width="80%" ></p>

<p>Kernel functions form a class of algorithms for pattern analysis. The main characteristic of kernel functions is a distinct approach to this problem.
Instead of reducing the dimension of the original data, kernel functions map the data into higher-dimensional spaces
in order to make the data more easily separable there.</p>

<p>Harp-DAAL currently supports batch mode of kernel functions for bothh of dense and sparse (CSR format) input datasets, which includes two sub-types</p>

<h3 id="linear-kernel">Linear Kernel</h3>

<p>A linear kernel is the simplest kernel function.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-linear-kernel">here</a>.</p>

<h3 id="radial-basis-function-kernel">Radial Basis Function Kernel</h3>

<p>The Radial Basis Function (RBF) kernel is a popular kernel function used in kernelized learning algorithms.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-radial-basis-function-kernel">here</a>.</p>

<p><a name="stumppos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="stump-weak-learner-classifier"><strong>Stump Weak Learner Classifier</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/stump-weaklearner.png" width="80%" ></p>

<p>A decision stump is a model that consists of a one-level decision tree <sup class="footnote-ref" id="fnref:fn14"><a rel="footnote" href="#fn:fn14">14</a></sup> where the root is connected to terminal nodes (leaves).</p>

<p>Harp-DAAL currently supports batch mode of Stump for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-32">here</a>.</p>

<p><a name="linregpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="linear-regression"><strong>Linear Regression</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/linear_regression.png" width="80%" ></p>

<p>In statistics, linear regression is an approach for modelling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Such models are called linear models.</p>

<p>Harp-DAAL currently supports distributed mode of linear regression for dense input datasets.
It has two algorithmic variants <sup class="footnote-ref" id="fnref:fn15"><a rel="footnote" href="#fn:fn15">15</a></sup>:</p>

<ul>
<li>Linear regression through normal equation</li>
<li>Linear regression through QR decomposition.</li>
</ul>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-linear-regression">here</a>.</p>

<p><a name="reregpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="ridge-regression"><strong>Ridge Regression</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/ridge-regression.png" width="80%" ></p>

<p>Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity. When
multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from
the true value. By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors.
It is hoped that the net effect will be to give estimates that are more reliable.</p>

<p>Harp-DAAL currently supports distributed mode of Ridge regression <sup class="footnote-ref" id="fnref:fn16"><a rel="footnote" href="#fn:fn16">16</a></sup> for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-ridge-regression">here</a>.</p>

<p><a name="alspos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="implicit-alternating-least-squares"><strong>Implicit Alternating Least Squares</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/als.png" width="80%" ></p>

<p>Alternating least squares (ALS) is an algorithm used in recommender systems,
which trains the model data X and Y to minimize the cost function as below</p>

<p><img src="https://dsc-spidal.github.io/harp/img/als-training-costfunction.png" width="50%" height="50%"><br>
<img src="https://dsc-spidal.github.io/harp/img/als-training-costfunction-2.png" width="30%" height="30%"><br></p>

<p>where</p>

<ul>
<li>c_ui measures the confidence in observing p_ui</li>
<li>alpha is the rate of confidence</li>
<li>r_ui is the element of the matrix R</li>
<li>labmda is the parameter of the regularization</li>
<li>n_xu, m_yi denote the number of ratings of user u and item i respectively.</li>
</ul>

<p>ALS alternatively computes model x and y independently of each other in the following formula:</p>

<p><img src="https://dsc-spidal.github.io/harp/img/als-x-compute-1.png" width="20%" height="20%"><br>
<img src="https://dsc-spidal.github.io/harp/img/als-x-compute-2.png" width="50%" height="50%"><br>
<img src="https://dsc-spidal.github.io/harp/img/als-y-compute-1.png" width="20%" height="20%"><br>
<img src="https://dsc-spidal.github.io/harp/img/als-y-compute-2.png" width="50%" height="50%"><br></p>

<p>Harp-DAAL currently supports distributed mode of ALS <sup class="footnote-ref" id="fnref:fn17"><a rel="footnote" href="#fn:fn17">17</a></sup><sup class="footnote-ref" id="fnref:fn18"><a rel="footnote" href="#fn:fn18">18</a></sup> for dense and sparse (CSR format) input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-details-38">here</a>.</p>

<p><a name="nnpos">
    <h1 style="padding-top: 60px; margin-top: -60px;"></h1>
</a></p>

<h2 id="neural-networks"><strong>Neural Networks</strong></h2>

<p><img src="https://dsc-spidal.github.io/harp/img/daalAlgos/nn.png" width="80%" ></p>

<p>Neural Networks are a beautiful biologically-inspired programming paradigm which enable a computer to learn from observational data.
The motivation for the development of neural network technology stemmed from the desire to develop an artificial system that could perform &ldquo;intelligent&rdquo; tasks similar to those performed by the human brain.
Neural networks, with their remarkable ability to derive meaning from complicated or imprecise data, can be used to extract patterns and detect trends that are too complex to be noticed by either humans or other computer techniques.</p>

<p>Harp-DAAL currently supports distributed mode of Neural Networks for dense input datasets.</p>

<p>More algorithmic details from Intel DAAL documentation is <a href="https://software.intel.com/en-us/daal-programming-guide-neural-networks">here</a>.</p>

<h2 id="references"><strong>References</strong></h2>
<div class="footnotes">

<hr />

<ol>
<li id="fn:fn1">Rakesh Agrawal, Ramakrishnan Srikant. Fast Algorithms for Mining Association Rules. Proceedings of the 20th VLDB Conference Santiago, Chile, 1994.
 <a class="footnote-return" href="#fnref:fn1"><sup>[return]</sup></a></li>
<li id="fn:fn2">Yoav Freund, Robert E. Schapire. Additive Logistic regression: a statistical view of boosting. Journal of Japanese Society for Artificial Intelligence (14(5)), 771-780, 1999.
 <a class="footnote-return" href="#fnref:fn2"><sup>[return]</sup></a></li>
<li id="fn:fn3">Jason D.M. Rennie, Lawrence, Shih, Jaime Teevan, David R. Karget. Tackling the Poor Assumptions of Naïve Bayes Text classifiers. Proceedings of the Twentieth International Conference on Machine Learning (ICML-2003), Washington DC, 2003.
 <a class="footnote-return" href="#fnref:fn3"><sup>[return]</sup></a></li>
<li id="fn:fn4">A.P.Dempster, N.M. Laird, and D.B. Rubin. Maximum-likelihood from incomplete data via the em algorithm. J. Royal Statist. Soc. Ser. B., 39, 1977.
 <a class="footnote-return" href="#fnref:fn4"><sup>[return]</sup></a></li>
<li id="fn:fn5">Trevor Hastie, Robert Tibshirani, Jerome Friedman. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Second Edition (Springer Series in Statistics), Springer, 2009. Corr. 7th printing 2013 edition (December 23, 2011).
 <a class="footnote-return" href="#fnref:fn5"><sup>[return]</sup></a></li>
<li id="fn:fn6">Bro, R.; Acar, E.; Kolda, T.. Resolving the sign ambiguity in the singular value decomposition. SANDIA Report, SAND2007-6422, Unlimited Release, October, 2007.
 <a class="footnote-return" href="#fnref:fn6"><sup>[return]</sup></a></li>
<li id="fn:fn7">Elad Hazan, John Duchi, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research, 12:21212159, 2011.
 <a class="footnote-return" href="#fnref:fn7"><sup>[return]</sup></a></li>
<li id="fn:fn8">R. H. Byrd, S. L. Hansen, Jorge Nocedal, Y. Singer. A Stochastic Quasi-Newton Method for Large-Scale Optimization, 2015. arXiv:1401.7020v2 [math.OC]. Available from <a href="http://arxiv.org/abs/1401.7020v2">http://arxiv.org/abs/1401.7020v2</a>.
 <a class="footnote-return" href="#fnref:fn8"><sup>[return]</sup></a></li>
<li id="fn:fn9">Mu Li, Tong Zhang, Yuqiang Chen, Alexander J. Smola. Efficient Mini-batch Training for Stochastic Optimization, 2014. Available from <a href="https://www.cs.cmu.edu/~muli/file/minibatch_sgd.pdf">https://www.cs.cmu.edu/~muli/file/minibatch_sgd.pdf</a>.
 <a class="footnote-return" href="#fnref:fn9"><sup>[return]</sup></a></li>
<li id="fn:fn10">David E. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams. Learning representations by back-propagating errors. Nature (323), pp. 533-536, 1986.
 <a class="footnote-return" href="#fnref:fn10"><sup>[return]</sup></a></li>
<li id="fn:fn11">B. E. Boser, I. Guyon, and V. Vapnik. A training algorithm for optimal marginclassiﬁers.. Proceedings of the Fifth Annual Workshop on Computational Learning Theory, pp: 144–152, ACM Press, 1992.
 <a class="footnote-return" href="#fnref:fn11"><sup>[return]</sup></a></li>
<li id="fn:fn12">Gareth James, Daniela Witten, Trevor Hastie, and Rob Tibshirani. An Introduction to Statistical Learning with Applications in R. Springer Series in Statistics, Springer, 2013 (Corrected at 6th printing 2015).
 <a class="footnote-return" href="#fnref:fn12"><sup>[return]</sup></a></li>
<li id="fn:fn13">Md. Mostofa Ali Patwary, Nadathur Rajagopalan Satish, Narayanan Sundaram, Jialin Liu, Peter Sadowski, Evan Racah, Suren Byna, Craig Tull, Wahid Bhimji, Prabhat, Pradeep Dubey. PANDA: Extreme Scale Parallel K-Nearest Neighbor on Distributed Architectures, 2016. Available from <a href="https://arxiv.org/abs/1607.08220">https://arxiv.org/abs/1607.08220</a>.
 <a class="footnote-return" href="#fnref:fn13"><sup>[return]</sup></a></li>
<li id="fn:fn14">Wayne Iba, Pat Langley. Induction of One-Level Decision Trees. Proceedings of Ninth International Conference on Machine Learning, pp: 233-240, 1992.
 <a class="footnote-return" href="#fnref:fn14"><sup>[return]</sup></a></li>
<li id="fn:fn15">Trevor Hastie, Robert Tibshirani, Jerome Friedman. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Second Edition (Springer Series in Statistics), Springer, 2009. Corr. 7th printing 2013 edition (December 23, 2011).
 <a class="footnote-return" href="#fnref:fn15"><sup>[return]</sup></a></li>
<li id="fn:fn16">Arthur E. Hoerl and Robert W. Kennard. Ridge Regression: Biased Estimation for Nonorthogonal Problems. Technometrics, Vol. 12, No. 1 (Feb., 1970), pp. 55-67.
 <a class="footnote-return" href="#fnref:fn16"><sup>[return]</sup></a></li>
<li id="fn:fn17">Rudolf Fleischer, Jinhui Xu. Algorithmic Aspects in Information and Management. 4th International conference, AAIM 2008, Shanghai, China, June 23-25, 2008. Proceedings, Springer.
 <a class="footnote-return" href="#fnref:fn17"><sup>[return]</sup></a></li>
<li id="fn:fn18">Yifan Hu, Yehuda Koren, Chris Volinsky. Collaborative Filtering for Implicit Feedback Datasets. ICDM&rsquo;08. Eighth IEEE International Conference, 2008.
 <a class="footnote-return" href="#fnref:fn18"><sup>[return]</sup></a></li>
</ol>
</div>
</article></section></div></div></div><script src="https://code.jquery.com/jquery-2.2.1.min.js"></script><script src="https://dsc-spidal.github.io/harp/js/app.min.js"></script></body></html>